{
  "model_name": "tinyllama",
  "model_id": "tinyllama:latest",
  "provider": "ollama",
  "storage_path": "shared/llm/tinyllama",
  "default_options": {
    "temperature": 0.2,
    "top_p": 0.6,
    "top_k": 20,
    "num_predict": 100,
    "repeat_penalty": 1.1
  },
  "concise_options": {
    "temperature": 0.1,
    "top_p": 0.5,
    "top_k": 10,
    "num_predict": 50,
    "repeat_penalty": 1.2
  },
  "version": "1.0.0",
  "description": "TinyLlama model configuration for shared services plane. Lower temperature (0.2) for more direct, concise responses."
}

